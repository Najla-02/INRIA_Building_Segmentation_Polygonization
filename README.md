## Objectif du projet

L'objectif de ce projet est de d√©velopper un pipeline de traitement d'images a√©riennes pour d√©tecter automatiquement les b√¢timents √† partir d'images satellites haute r√©solution.

Le projet est divis√© en deux √©tapes majeures :
- **Segmentation s√©mantique** des b√¢timents avec un mod√®le de Deep Learning (U-Net).
- **Polygonisation** des masques pr√©dis afin d'obtenir des contours vectoriels exploitables.

Le travail a √©t√© men√© dans le cadre du module *Mod√©lisation syst√®mes vision*.

## Donn√©es utilis√©es

Les donn√©es utilis√©es proviennent du jeu de donn√©es public **INRIA Aerial Image Labeling Dataset**.

- R√©solution spatiale : 0.3 m/pixel
- Taille des images : 5000x5000 pixels (d√©coup√©es en sous-patches 256x256 pour l'entra√Ænement)
- 5 villes am√©ricaines diff√©rentes sont repr√©sent√©es (Austin, Chicago, Kitsap County, Western Tyrol, Vienna)

**Lien vers les donn√©es officielles :**  
üîó [INRIA Aerial Image Labeling Dataset](https://project.inria.fr/aerialimagelabeling/)

Les annotations disponibles sont des masques binaires o√π les b√¢timents sont repr√©sent√©s en blanc.

![Dataset exemple 1](figures/dataset.png)

![Dataset exemple 2](figures/dataset2.png)

## M√©thodologie

Le projet a √©t√© r√©alis√© en plusieurs √©tapes successives :

### 1. Pr√©traitement des donn√©es

- D√©coupage des grandes images en sous-patches de 256x256 pixels.
- S√©lection des patches contenant des b√¢timents pour √©quilibrer les classes.
- Normalisation des images.

### 2. Data Augmentation

Afin d‚Äôaugmenter la diversit√© des donn√©es d‚Äôapprentissage :
- Rotations al√©atoires
- Zoom
- Renversements horizontaux et verticaux

### 3. Mod√®le de segmentation s√©mantique

- Architecture utilis√©e : **U-Net**
- Fonction de perte : combinaison de Dice Loss et Binary Crossentropy, pond√©r√©e pour corriger le d√©s√©quilibre.
- Optimisation via Adam.

![Architecture U-Net](figures/U-NET.webp)

### 4. Post-traitement

- Filtrage des petites zones pr√©dites inf√©rieures √† un seuil de surface.
- Extraction des contours et conversion des masques en polygones via les biblioth√®ques `skimage` et `shapely`:

- Apr√®s la segmentation s√©mantique binaire des b√¢timents, un post-traitement de polygonisation est appliqu√© pour convertir les masques de segmentation en objets vectoriels exploitables.
- Les masques pr√©dits sont d‚Äôabord binaris√©s.
- Puis, les contours sont extraits gr√¢ce √† la d√©tection de contours.
- Les contours sont transform√©s en polygones g√©om√©triques via la biblioth√®que shapely.
- Enfin, les petits objets inf√©rieurs √† un seuil de surface sont filtr√©s pour √©viter les faux positifs.

![Polygonisation finale](figures/Polygonisation finale.png)  

### 5. √âvaluation des performances

Les performances du mod√®le sont √©valu√©es √† l‚Äôaide de plusieurs m√©triques classiques de segmentation binaire :

- Dice coefficient (F1 Score)
- Intersection over Union (IoU)
- Pr√©cision
- Rappel
  
![R√©sultats d'√©valuation](figures/resultats √©valuation.png)

![R√©sultats de pr√©diction 1](figures/resultats_prediction.png)

![R√©sultats de pr√©diction 2](figures/resultats_prediction2.png)

## 6. Contenu du d√©p√¥t

- `notebook/` : Notebook complet du pipeline de segmentation et de polygonisation.
- `models/` : Mod√®le entra√Æn√© sauvegard√© au format Keras.
- `results/` : Exemples visuels de segmentation et de polygonisation.
- `data/` : (lien ‚Äî le dataset INRIA est disponible publiquement via le lien indiqu√© plus haut).
- `requirements.txt` : Liste des d√©pendances n√©cessaires pour ex√©cuter le projet.


